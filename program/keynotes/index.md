---
layout: default
slug: keynotes
---
<div class="row">
 <div class="col-md-11" markdown="1">

<div class="row">
<h1>Keynote Speakers for MODELS 2018</h1>
</div>
<div class="row" id="seres">
<h2> Noelle Eckley Selin - Modeling air pollution: Informing policies to address a global environmental challenge</h2>
<img align="left" src="/assets/faces/nselin.jpg" alt="Noelle Eckley Selin" class="team-face" style="margin-right: 20px"/> 
 
<p>
Air pollution is a leading cause of global mortality: according to the World Health Organization, 90% of people worldwide breathe polluted air, and outdoor air pollution causes over 4 million deaths annually. Different models can simulate various aspects of the air pollution problem by quantifying pollutant emissions from different sectors and their socio-economic drivers, tracing the chemistry and transport of atmospheric processes, attributing pollutant concentrations to specific sources, and quantifying the health and economic burdens of pollutant exposure. To inform efforts to mitigate air pollution, however, we need to trace the entire pathway by which policies to address emissions translate into societal benefits. Doing this requires connecting models from different academic fields, and which exist in different modeling languages, with different temporal and spatial scales, and with different core scientific assumptions. In this talk, I summarize work from my research group evaluating the impacts of air pollution policies by connecting and integrating models across this conceptual chain. Examples provided include assessing the air pollution and related health impacts of proposed policies to address climate change in the U.S. and China, and quantifying the domestic and international benefits of mercury reduction policies in China, India, and the U.S. Technical challenges of linking models include accounting for issues of temporal and spatial scale, complexity, and boundaries. Effectively informing decision-making, however, also requires that decision-makers see models as credible, salient, and legitimate. Thus, I also describe ways in which we have engaged with stakeholders and decision-makers, and examine how these efforts have influenced the impact of this research on policy.
</p>
<p>
<h3> Bio </h3>
Noelle Eckley Selin is Associate Professor in the Institute for Data, Systems and Society and the Department of Earth, Atmospheric and Planetary Sciences at the Massachusetts Institute of Technology. She is also Director of MIT's Technology and Policy Program. Her research uses atmospheric chemistry modeling to inform decision-making on air pollution, climate change and hazardous substances such as mercury and persistent organic pollutants (POPs). She received her PhD from Harvard University in Earth and Planetary Sciences as part of the Atmospheric Chemistry Modeling Group. Her M.A. (Earth and Planetary Sciences) and B.A. (Environmental Science and Public Policy) are also from Harvard University. Before joining the MIT faculty, she was a research scientist with the MIT Joint Program on the Science and Policy of Global Change.  She has published 70+ articles in the peer-reviewed literature, addressing atmospheric chemistry, air pollution, and interactions between science and policy in international environmental negotiations. Her articles were selected as the best environmental policy papers in 2015 and 2016 by the journal Environmental Science & Technology.  She is the recipient of a U.S. National Science Foundation CAREER award (2011), a Leopold Leadership fellow (2013-2014), Kavli fellow (2015), a member of the Global Young Academy (2014-2018), an American Association for the Advancement of Science Leshner Leadership Institute Fellow (2016-2017), and a Hans Fischer Senior Fellow at the Technical University of Munich Institute for Advanced Study (2018-2021).
</p>
</div> 

<hr>
<div class="row" id="cordy">
<h2> Jim Cordy - Genetics of Computer Programs</h2>
<img align="right" src="/assets/faces/jcordy.jpg" alt="Jim Cordy" class="team-face" style="margin-right: 20px; "/>
 
<p> 
Language use vectors (LUVs) encode the vocabulary and frequency of programming language 
feature use by computer programs and applications. In some sense, they encode the potential 
and expressed vocabulary of a program in a way analogous to the way that the genome (DNA) 
and phenome (RNA) describe the potential and expressed properties of a living thing. 
In this talk I will explore this analogy and its potential for predicting hidden properties of programs,
models and applications such as changes, faults and security flaws.
 
</p>
<h3> Bio </h3>
James R. Cordy is Professor and past Director of the School of Computing at Queen's University in Kingston, Ontario, Canada, and Director of the NSERC CREATE Graduate Specialization in Ultra-Large Scale Software Systems.  From 1995 to 2000 he was Vice President and Chief Research Scientist at Legasys Corporation, a software technology company specializing in legacy software system analysis and renovation.  As leader of the TXL source transformation project with hundreds of academic and industrial users worldwide, he has been involved in computer software analysis and transformation systems for more than 30 years.  

Dr. Cordy has published more than 200 refereed contributions in software engineering, programming languages and artificial intelligence, an in the past five years has been invited as keynote speaker at the IEEE International Conference on Software Maintenance and Evolution, the IEEE International Conference on Software Product Lines, the International Workshop on Automotive Software Architecture, and the International Workshop on Open and Original Problems in Software Language Engineering. He serves widely as member and chair of conferences, workshops and evaluation committees in software engineering, and has received multiple Best Reviewer awards. 

Dr. Cordy is a Senior Member of the IEEE, a Distinguished Scientist of the Association for Computing Machinery and an IBM Visiting Scientist and Faculty Fellow. He was recognized as IBM Centre for Advanced Studies Faculty Fellow of the Year in both 2009 and 2013.  In 2008 he received the Queen’s University Award for Excellence in Graduate Supervision, and in 2016 the Queen’s University Prize for Excellence in Research.

In recent years Dr. Cordy’s research group has concentrated on similarity in software systems, with particular application to model-driven systems in Simulink using the SIMONE near-miss model clone detector. Most recently, he has been studying profiles of language feature use in transformation languages such as TXL and ATL, with an eye to informing the future of model transformation systems.
</div>
<hr>
<div class="row" id="wisse">
<h2> Martijn Wisse -  Models for motion prediction; robotic brains versus biological brains</h2>
<img align="left" src="/assets/faces/mwisse.jpg" alt="Martijn Wisse" class="team-face" style="margin-right: 20px;" />
 
This talk will focus on robot and animal motions. For any system in the real world (robots, animals, and humans alike), for any task that they need to execute, the world needs to be predictable. Accurate predictions facilitate anticipation, planning, and optimization. And predictions are made with a model, i.e. a description of (relevant parts of) the world written in a well-defined language. So the key question for this talk is which models and which modelling language are used by robots and by the biological brain, and is there any similarity between the two?
<br>
<br>
We will first review which models and which language are used for the prediction of dynamic motions for robots. We will survey the basics of (systems of) differential equations illustrated with our work on walking robots, self-driving cars, robotic arms, hands, and integrated systems for logistic applications (the "Amazon Picking Challenge").
<br>
<br>
Next, in this presentation we survey the reigning neuroscientific theories for how the brain does modelling and prediction. Prediction will appear to play a deep fundamental role in all of our brain functions, and we will analyse how this is related to the robot approach; the brain has no processing unit for matrix multiplications or differential equations, so how does the brain do dynamic prediction?
<br>
<br>
Finally, we will share a preliminary breakthrough result termed "Dualistic Prediction Error Minimization", a key insight from the brain's ways of prediction error minimization, which will allow for a tremendous improvement in modelling accuracy for our future complex robot systems that require predictability within a complex environment.

<h3> Bio </h3>
Martijn Wisse is Professor of Biorobotics and Director of the Robotics Institute at Delft University of Technology, The Netherlands. He has co-founded the TU Delft Robotics Institute, the robotics ecosystem “RoboValley”, and the two successful spin-off companies Lacquey (now FTNON Lacquey) and Fizyr. He served as the coordinator of the EU FP7 project “Factory-in-a-Day” and currently coordinates the EU H2020 project “ROSIN” which focuses on the open-source robot software framework ROS-Industrial.  

The research of prof. Wisse has led from passive dynamic two-legged walking robots via biologically inspired underactuated robot hands and arms to the use of ROS-Industrial and deep learning for intelligent industrial robot systems. A recent highlight was winning the 2016 edition of the Amazon Picking Challenge which required the combination of 3D vision, object recognition, motion planning, and robust localization. Currently, prof. Wisse is working in the field of Active Inference, where he aims to combine information-theoretic models of the neural operations of the biological brain with practical implementations in embodied robots. The ultimate aim is to give the robots an automated way to infer models of themselves and their environment, and simultaneously to learn how to control themselves, in order to maximize their success at predicting their future sensor inputs.
</div>
</div>
</div>


